{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b4f23e3-0efd-40bf-a7c3-40f96d3dc45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nemo-microservices==1.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d027a76",
   "metadata": {},
   "source": [
    "# Register Model Configuration\n",
    "- In NeMoMicroservices client, set base_url to nemo-deployment-management's url\n",
    "- To register MLIS's model endpoint, we need URL, API Token, Model Name\n",
    "\n",
    "```json\n",
    "    {\n",
    "        \"host_url\": \"<URL>\",\n",
    "        \"api_key\": \"<API Token>\",\n",
    "        \"enabled_models\": [\"<Model Name>\"]\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3e89632-c51c-4bb8-8995-21beae86d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo_microservices import NeMoMicroservices\n",
    "\n",
    "deploy_client = NeMoMicroservices(\n",
    "    base_url='http://nemo-deployment-management:8000',\n",
    "    inference_base_url='http://nemo-nim-proxy:8000'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e402b6-e43f-4338-be47-370aa033e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_client.deployment.configs.create(\n",
    "    name=\"mlis-llama-31-8b-instruct\",\n",
    "    namespace=\"mlis\",\n",
    "    description=\"mlis endpoint configuration\",\n",
    "    external_endpoint={\n",
    "        \"host_url\": \"https://llm-llama-3-1-8b-predictor-user.app.pcai.XXXX\",\n",
    "        \"api_key\": \"<put MLIS's endpoint token>\",\n",
    "        \"enabled_models\": [\n",
    "            \"meta/llama-3.1-8b-instruct\"\n",
    "        ]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc7693-fdcf-4180-a795-b7f67f842bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_client.deployment.configs.create(\n",
    "    name=\"mlis-qwen-25-7b-instruct\",\n",
    "    namespace=\"mlis\",\n",
    "    description=\"mlis endpoint configuration\",\n",
    "    external_endpoint={\n",
    "        \"host_url\": \"https://qwen-25-7b-instruct-stream-predictor-user.app.pcai.XXXX\",\n",
    "        \"api_key\": \"<put MLIS's endpoint token>\",\n",
    "        \"enabled_models\": [\n",
    "            \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "        ]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b64f91a-203c-49d5-ac13-c64f4772b7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_client.inference.models.list().dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1243afca-9234-4a48-977e-46a1082438d9",
   "metadata": {},
   "source": [
    "# Inference with nim-proxy url\n",
    "- Once the Model configuration is successfully registered, we can use **nim-proxy url** to do inference for that model with same token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3355bddc-df89-4b4b-90dd-d5a03f385b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_token = \"<put MLIS's endpoint token>\"\n",
    "qwen_token = \"<put MLIS's endpoint token>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1da5363-22ea-4c2e-bad7-41f938c5b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_profiles = [\n",
    "    {\n",
    "        \"api_key\": llama_token,\n",
    "        \"model_name\": \"meta/llama-3.1-8b-instruct\",\n",
    "    },\n",
    "    {\n",
    "        \"api_key\": qwen_token,\n",
    "        \"model_name\": \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "801e8afa-d85b-471b-bd8d-2af948bdd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://nemo-nim-proxy:8000' + '/v1/chat/completions'\n",
    "\n",
    "responses = []\n",
    "\n",
    "for model in model_profiles:\n",
    "    headers = {\n",
    "        'Authorization':'Bearer ' + model['api_key']\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model['model_name'],\n",
    "        \"messages\": [{\"role\":\"user\", \"content\":\"Write a limerick about the wonders of GPU computing.\"}],\n",
    "        \"max_tokens\": 128\n",
    "    }\n",
    "    responses.append(requests.post(url=url,headers=headers,json=payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "042da9cc-bab7-4003-bc4e-1a77aeb84ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in responses:\n",
    "    print(f\"*** {i.json()['model']} ***\")\n",
    "    print(i.json()['choices'][0]['message']['content'])\n",
    "    print('=' * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gymtest",
   "language": "python",
   "name": "gymtest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
